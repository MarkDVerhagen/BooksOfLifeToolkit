# server help: https://github.com/ggerganov/llama.cpp/tree/master/examples/server

llama-server \
--hf-repo microsoft/Phi-3-mini-4k-instruct-gguf \
--hf-file Phi-3-mini-4k-instruct-q4.gguf 


llama-server \
  --model models/Phi-3-mini-4k-instruct-q4.gguf 