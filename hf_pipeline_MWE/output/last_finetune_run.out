wandb: Tracking run with wandb version 0.17.4
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
/scratch/gpfs/vs3041/prefer_prepare/hf_pipeline_MWE/scripts/fine_tuning_with_hf.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data["labels"] = (data["labels"] == "kid: 1").astype(int)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:06,  6.04s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.90s/it]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /scratch/gpfs/vs3041/prefer_prepare/hf_pipeline_MWE/hf_models/Meta-Llama-3-8B/ and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
PEFT Model
trainable params: 13,639,680 || all params: 7,518,572,544 || trainable%: 0.1814
Map:   0%|          | 0/600 [00:00<?, ? examples/s]Map: 100%|██████████| 600/600 [00:00<00:00, 1982.46 examples/s]Map: 100%|██████████| 600/600 [00:00<00:00, 1913.70 examples/s]
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: WARNING URL not available in offline run
  0%|          | 0/300 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  0%|          | 1/300 [00:04<22:21,  4.49s/it]  1%|          | 2/300 [00:08<20:20,  4.10s/it]  1%|          | 3/300 [00:12<19:40,  3.98s/it]  1%|▏         | 4/300 [00:15<19:19,  3.92s/it]  2%|▏         | 5/300 [00:19<19:06,  3.89s/it]  2%|▏         | 6/300 [00:23<18:57,  3.87s/it]  2%|▏         | 7/300 [00:27<18:50,  3.86s/it]  3%|▎         | 8/300 [00:31<18:44,  3.85s/it]  3%|▎         | 9/300 [00:35<18:39,  3.85s/it]  3%|▎         | 10/300 [00:38<18:35,  3.85s/it]  4%|▎         | 11/300 [00:42<18:31,  3.85s/it]  4%|▍         | 12/300 [00:46<18:28,  3.85s/it]  4%|▍         | 13/300 [00:50<18:24,  3.85s/it]