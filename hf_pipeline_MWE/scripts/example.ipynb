{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, load_from_disk, Dataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model, LoraConfig, AutoPeftModelForSequenceClassification\n",
    "import argparse\n",
    "import pandas as pd \n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting wandb to offline\n",
    "wandb.init(mode=\"offline\")   \n",
    "\n",
    "def format_salganik_data(data):\n",
    "\n",
    "    ## Taking csv and turning it into HF format\n",
    "\n",
    "    # HF needs a specific form for the dataset\n",
    "    data[\"text\"] = data[\"input\"]\n",
    "    data[\"labels\"] = data[\"output\"]\n",
    "\n",
    "    # keeping only inputs and outputs\n",
    "    data = data[[\"text\", \"labels\"]]\n",
    "\n",
    "    # making sure outputs are 0s and 1s (will need to make this programatic)\n",
    "    data[\"labels\"] = (data[\"labels\"] == \"kid: 1\").astype(int)  \n",
    "\n",
    "    # converting to HF format\n",
    "    data = Dataset.from_pandas(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_unique_id(filename):\n",
    "\n",
    "    # extract from books of life \n",
    "    if \"bol/\" in filename:\n",
    "        start = filename.index('bol/') + len('bol/')\n",
    "        end = filename.index('.txt')\n",
    "\n",
    "    elif \"outcome/\" in filename:\n",
    "        start = filename.index('outcome/') + len('outcome/')\n",
    "        end = filename.index('.txt')\n",
    "    else: \n",
    "        ValueError(\"Can't find unique id from filename\")\n",
    "    \n",
    "    return filename[start:end]\n",
    "\n",
    "def format_BOL_data(path_to_training_data):\n",
    "    \n",
    "    # Step 1: reading in books of life\n",
    "\n",
    "    # the books of life are contained in multiple .txt files \n",
    "    BOL_txt_files = glob.glob(path_to_training_data + \"bol/\" + '*.txt')\n",
    "\n",
    "    books_of_life = []\n",
    "    unique_ids = []\n",
    "    data = []\n",
    "\n",
    "    for txt_file in BOL_txt_files:\n",
    "\n",
    "        #reading books of life\n",
    "        with open(txt_file, 'r') as infile:\n",
    "            book_of_life = infile.read().strip()\n",
    "            unique_id = extract_unique_id(txt_file)     # extract unique_id from filename\n",
    "\n",
    "        \n",
    "        # reading outcomes\n",
    "        outcome_txt_file = path_to_training_data + \"outcome/\" + unique_id + '.txt'\n",
    "        with open(outcome_txt_file, 'r') as infile:\n",
    "            outcome = infile.read().strip()\n",
    "\n",
    "        data_for_unique_id = {\n",
    "            \"text\": book_of_life,\n",
    "            \"unique_id\": unique_id,\n",
    "            \"labels\": int(outcome)\n",
    "        }\n",
    "\n",
    "        data.append(data_for_unique_id)\n",
    "\n",
    "    # added with_format(\"torch\")\n",
    "    data = Dataset.from_list(data).with_format(\"torch\")\n",
    "\n",
    "    # batching for accelerate \n",
    "    data = DataLoader(data, batch_size=4)\n",
    "\n",
    "    return data\n",
    "\n",
    "def tokenize_and_prepare(data):\n",
    "\n",
    "    # Tokenizer for HF models\n",
    "\n",
    "    return tokenizer(data[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# model arguments from the command line\n",
    "\n",
    "model_name = os.environ.get('model_name')\n",
    "dataset = os.environ.get('dataset')\n",
    "fine_tune_method = os.environ.get('fine_tune_method')\n",
    "GPU_util = os.environ.get('GPU_util')\n",
    "params = os.environ.get('params')\n",
    "training_folds = os.environ.get('training_folds')\n",
    "first_training_fold, last_training_fold = map(int, training_folds.split(\"-\"))\n",
    "\n",
    "project_directory = os.environ.get('project_path') + \"/\"\n",
    "\n",
    "fine_tuned_model_name = \"-\".join([model_name, dataset, fine_tune_method, GPU_util, params, \"folds\", training_folds])\n",
    "output_directory = project_directory + \"fine_tuned_models/\" + fine_tuned_model_name\n",
    "\n",
    "#### SPECIFIYING MODEL\n",
    "\n",
    "if model_name == \"llama3-8b\":\n",
    "    model_to_read = project_directory + \"hf_models/\" + \"Meta-Llama-3-8B/\"\n",
    "else: \n",
    "    raise Exception(\"Either the model is the wrong place, or we haven't downloaded it yet :(\")\n",
    "\n",
    "\n",
    "#### SPECIFIYING DATA\n",
    "\n",
    "if dataset == \"salganik\":\n",
    "    # reading training data \n",
    "    data_to_read = project_directory + \"data/salganik_data.csv\"\n",
    "    train_dataset = pd.read_csv(data_to_read)\n",
    "\n",
    "    # subsetting data to specified training folds \n",
    "    train_dataset = train_dataset[train_dataset['fold'].between(first_training_fold, last_training_fold)]\n",
    "\n",
    "    # formatting the salganik data to get it into a format readable by the LLM\n",
    "    train_dataset = format_salganik_data(train_dataset)    \n",
    "\n",
    "    print(\"using Salganik data\")\n",
    "\n",
    "elif dataset == \"bol-temp-1\" or dataset == \"bol-temp-2\":\n",
    "    data_to_read =  \"/scratch/gpfs/vs3041/prefer_prepare/synth/data/e2e/test_template1/train/\"\n",
    "\n",
    "    train_dataset = format_BOL_data(data_to_read)\n",
    "\n",
    "    print(\"Using\" + dataset)\n",
    "\n",
    "    print(\"samples = \" + str(len(train_dataset)))\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Dataset not recognised\")\n",
    "\n",
    "#### SPECIFIYING FINE-TUNING METHOD\n",
    "\n",
    "if fine_tune_method == \"full\":\n",
    "    pass\n",
    "elif fine_tune_method == \"lora\":\n",
    "    pass\n",
    "else: \n",
    "    raise Exception(\"Haven't written code to support other fine-tune methods yet\")\n",
    "\n",
    "\n",
    "#### SPECIFIYING GPU UTILIZATION\n",
    "\n",
    "if GPU_util == \"single\":\n",
    "    pass\n",
    "else: \n",
    "    raise Exception(\"Haven't written code to support distributed GPU utilization yet\")\n",
    "\n",
    "\n",
    "#### ADDING CUSTOM HYPERPARAMETERS\n",
    "\n",
    "if params == \"default\":\n",
    "    pass\n",
    "else: \n",
    "    raise Exception(\"Haven't written code to change parameters yet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
